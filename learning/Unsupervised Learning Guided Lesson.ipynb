{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Unsupervised-Learning-Guided-Lesson\" data-toc-modified-id=\"Unsupervised-Learning-Guided-Lesson-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Unsupervised Learning Guided Lesson</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lesson-Goals\" data-toc-modified-id=\"Lesson-Goals-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Lesson Goals</a></span></li><li><span><a href=\"#Exploring-the-Variables\" data-toc-modified-id=\"Exploring-the-Variables-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exploring the Variables</a></span></li><li><span><a href=\"#Some-More-Transformations---PCA\" data-toc-modified-id=\"Some-More-Transformations---PCA-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Some More Transformations - PCA</a></span></li><li><span><a href=\"#The-Algorithm---K-Means-Clustering\" data-toc-modified-id=\"The-Algorithm---K-Means-Clustering-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>The Algorithm - K-Means Clustering</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Guided Lesson\n",
    "\n",
    "\n",
    "## Lesson Goals\n",
    "\n",
    "In this guided lesson, we will analyze an unsupervised learning problem from start to finish and introduce several different processing techniques.\n",
    "\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "As a data scientist or analyst, you may be asked open ended question about a dataset. One example is to find some patterns in a dataset that is unlabeled. Typically, this happens when analyzing a group of customers and trying to find a common themes between the transactions. The leading choice of algorithm for this type of problem is an unsupervised algorithm. Specifically, this lesson will be using clustering to analyze this problem. In this lesson, we will be analyzing a log of transactions from a bakery to make recommendations about the marketing and sale of products.\n",
    "\n",
    "\n",
    "**The Data**\n",
    "\n",
    "The dataset we will be analyzing comes from Kaggle and is a log of transactions from a bakery in Edinburgh called The Bread Basket. We will start by evaluating the types of the variables in the data as well as the contents of the categorical variables and the distribution of the numerical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           object\n",
       "Time           object\n",
       "Transaction     int64\n",
       "Item           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "breadbasket = pd.read_csv('../data/BreadBasket_DMS.csv')\n",
    "breadbasket.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>09:58:11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Hot chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Jam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Transaction           Item\n",
       "0  2016-10-30  09:58:11            1          Bread\n",
       "1  2016-10-30  10:05:34            2   Scandinavian\n",
       "2  2016-10-30  10:05:34            2   Scandinavian\n",
       "3  2016-10-30  10:07:57            3  Hot chocolate\n",
       "4  2016-10-30  10:07:57            3            Jam"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breadbasket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4951.990889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2787.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9684.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Transaction\n",
       "count  21293.000000\n",
       "mean    4951.990889\n",
       "std     2787.758400\n",
       "min        1.000000\n",
       "25%     2548.000000\n",
       "50%     5067.000000\n",
       "75%     7329.000000\n",
       "max     9684.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breadbasket.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from these three functions, we have 4 columns in the dataset. The date and time are separated into two columns and stored as text. This means we will have to combine and convert them later on. The transaction variable is ordinal, so the summary statistics really have no meaning in this context. The only meaningful information from the describe function is the max which tells us we have 9684 transactions in the dataset. From the head function, we see that each row represents an item in the transaction. This means that there are potentially multiple items per transaction or maybe just one. We might benefit from consolidating the data and creating a new dataset that contains one row per transaction.\n",
    "\n",
    "So the data we have is a breakdown of each item in a transaction and the date and time when the transaction occurred. The data we do not have is any information about the customer. Since we cannot associate the transactions back to customers, we cannot tell if a certain customer is a regular who comes in and buys a coffee and a pastry every day or whether a customer is a tourist who came in once and bought a specialty dessert.\n",
    "\n",
    "Our strategy to make sense of the dataset will be to generate derived variables from this transaction log and cluster based on these derived variables. We will evaluate the aggregate information regarding each cluster and make recommendations about which products to advertise and which products should be in stock and at what days and times.\n",
    "\n",
    "\n",
    "## Exploring the Variables\n",
    "\n",
    "While we only have a few variables, we should explore their contents.\n",
    "\n",
    "First, let's look at the time and day of week. Hour is a crucial factor since customer behavior differs significantly between the morning and the afternoon. However, we can even find differences between customer behavior at 7 am vs. at 9 am. Similarly, we see differences between weekday and weekend customer behavior.\n",
    "\n",
    "To examine the date and time, we must reformat this variable. We start by combining the date and time into one column and then transforming the column to a datetime column. This allows us to extract the hour and the time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "breadbasket['DateTime'] = pd.to_datetime(breadbasket.Date + ' ' + breadbasket.Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the item variable. This variable will tell us how many products are sold by the bakery and which products are more popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bread', 'Scandinavian', 'Hot chocolate', 'Jam', 'Cookies',\n",
       "       'Muffin', 'Coffee', 'Pastry', 'Medialuna', 'Tea', 'NONE',\n",
       "       'Tartine', 'Basket', 'Mineral water', 'Farm House', 'Fudge',\n",
       "       'Juice', \"Ella's Kitchen Pouches\", 'Victorian Sponge', 'Frittata',\n",
       "       'Hearty & Seasonal', 'Soup', 'Pick and Mix Bowls', 'Smoothies',\n",
       "       'Cake', 'Mighty Protein', 'Chicken sand', 'Coke',\n",
       "       'My-5 Fruit Shoot', 'Focaccia', 'Sandwich', 'Alfajores', 'Eggs',\n",
       "       'Brownie', 'Dulce de Leche', 'Honey', 'The BART', 'Granola',\n",
       "       'Fairy Doors', 'Empanadas', 'Keeping It Local', 'Art Tray',\n",
       "       'Bowl Nic Pitt', 'Bread Pudding', 'Adjustment', 'Truffles',\n",
       "       'Chimichurri Oil', 'Bacon', 'Spread', 'Kids biscuit', 'Siblings',\n",
       "       'Caramel bites', 'Jammie Dodgers', 'Tiffin', 'Olum & polenta',\n",
       "       'Polenta', 'The Nomad', 'Hack the stack', 'Bakewell',\n",
       "       'Lemon and coconut', 'Toast', 'Scone', 'Crepes', 'Vegan mincepie',\n",
       "       'Bare Popcorn', 'Muesli', 'Crisps', 'Pintxos', 'Gingerbread syrup',\n",
       "       'Panatone', 'Brioche and salami', 'Afternoon with the baker',\n",
       "       'Salad', 'Chicken Stew', 'Spanish Brunch',\n",
       "       'Raspberry shortbread sandwich', 'Extra Salami or Feta',\n",
       "       'Duck egg', 'Baguette', \"Valentine's card\", 'Tshirt',\n",
       "       'Vegan Feast', 'Postcard', 'Nomad bag', 'Chocolates',\n",
       "       'Coffee granules ', 'Drinking chocolate spoons ',\n",
       "       'Christmas common', 'Argentina Night', 'Half slice Monster ',\n",
       "       'Gift voucher', 'Cherry me Dried fruit', 'Mortimer', 'Raw bars',\n",
       "       'Tacos/Fajita'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breadbasket.Item.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the counts as well to see what items are most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item\n",
       "Coffee            5471\n",
       "Bread             3325\n",
       "Tea               1435\n",
       "Cake              1025\n",
       "Pastry             856\n",
       "                  ... \n",
       "Adjustment           1\n",
       "The BART             1\n",
       "Olum & polenta       1\n",
       "Gift voucher         1\n",
       "Raw bars             1\n",
       "Name: count, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breadbasket.Item.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 95 items. The most common items are coffee, bread, tea, cake and pastry. Since 95 is a really large number, if we created dummy variables out of this data, it would produce too many variables. One option is to classify the data. Typically, when working on these types of problems, companies will have a classification system for the items they sell. However, let's try to come up with our own.\n",
    "\n",
    "Looking at the list of unique items, we can identify a number of obvious categories. We have beverages and breakfast pastries like muffins and medialuna. We have items for kids like juice and pouches. We also have non food items like gift vouchers and t-shirts. Another group of items that we can notice is ready to eat snacks like popcorn and crisps. With a bit of work, we can narrow it down from 95 products to 11 categories: beverage, other, kids, snacks, bread, breakfast pastry, dessert, condiments, breakfast, lunch, and other foods. The last group is used to classify mostly uncommon items that sell very little (like polenta) or have names that are hard to identify (like \"Hack the Stack\").\n",
    "\n",
    "We generate the categories using lists and then use the lists to create dummy variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>beverage</th>\n",
       "      <th>other</th>\n",
       "      <th>kids</th>\n",
       "      <th>snacks</th>\n",
       "      <th>bread</th>\n",
       "      <th>breakfast_pastry</th>\n",
       "      <th>dessert</th>\n",
       "      <th>condiments</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>lunch</th>\n",
       "      <th>other_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>09:58:11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bread</td>\n",
       "      <td>2016-10-30 09:58:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>2016-10-30 10:05:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>2016-10-30 10:05:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Hot chocolate</td>\n",
       "      <td>2016-10-30 10:07:57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Jam</td>\n",
       "      <td>2016-10-30 10:07:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Transaction           Item            DateTime  \\\n",
       "0  2016-10-30  09:58:11            1          Bread 2016-10-30 09:58:11   \n",
       "1  2016-10-30  10:05:34            2   Scandinavian 2016-10-30 10:05:34   \n",
       "2  2016-10-30  10:05:34            2   Scandinavian 2016-10-30 10:05:34   \n",
       "3  2016-10-30  10:07:57            3  Hot chocolate 2016-10-30 10:07:57   \n",
       "4  2016-10-30  10:07:57            3            Jam 2016-10-30 10:07:57   \n",
       "\n",
       "   beverage  other  kids  snacks  bread  breakfast_pastry  dessert  \\\n",
       "0         0      0     0       0      1                 0        0   \n",
       "1         0      0     0       0      1                 0        0   \n",
       "2         0      0     0       0      1                 0        0   \n",
       "3         1      0     0       0      0                 0        0   \n",
       "4         0      0     0       0      0                 0        0   \n",
       "\n",
       "   condiments  breakfast  lunch  other_food  \n",
       "0           0          0      0           0  \n",
       "1           0          0      0           0  \n",
       "2           0          0      0           0  \n",
       "3           0          0      0           0  \n",
       "4           1          0      0           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beverage = ['Hot chocolate', 'Coffee', 'Tea', 'Mineral water', 'Juice', 'Coke', 'Smoothies']\n",
    "other = ['NONE', 'Christmas common', 'Gift voucher', \"Valentine's card\", 'Tshirt', 'Afternoon with the baker', 'Postcard', 'Siblings', 'Nomad bag', 'Adjustment', 'Drinking chocolate spoons ', 'Coffee granules ']\n",
    "kids = [\"Ella's Kitchen Pouches\", 'My-5 Fruit Shoot', 'Kids biscuit']\n",
    "snacks = ['Mighty Protein', 'Pick and Mix Bowls', 'Caramel bites', 'Bare Popcorn', 'Crisps', 'Cherry me Dried fruit', 'Raw bars']\n",
    "bread = ['Bread', 'Toast', 'Baguette', 'Focaccia', 'Scandinavian']\n",
    "breakfast_pastry = ['Muffin', 'Pastry', 'Medialuna', 'Scone']\n",
    "dessert = ['Cookies', 'Tartine', 'Fudge', 'Victorian Sponge', 'Cake', 'Alfajores', 'Brownie', 'Bread Pudding', 'Bakewell', 'Raspberry shortbread sandwich', 'Lemon and coconut', 'Crepes', 'Chocolates', 'Truffles', 'Panatone']\n",
    "condiments = ['Jam', 'Dulce de Leche', 'Honey', 'Gingerbread syrup', 'Extra Salami or Feta', 'Bacon', 'Spread', 'Chimichurri Oil']\n",
    "breakfast = ['Eggs', 'Frittata', 'Granola', 'Muesli', 'Duck egg', 'Brioche and salami']\n",
    "lunch = ['Soup', 'Sandwich', 'Chicken sand', 'Salad', 'Chicken Stew']\n",
    "\n",
    "\n",
    "other_food = [x for x in breadbasket.Item.unique() if x not in beverage \n",
    "                and x not in other and x not in kids and x not in snacks \n",
    "                and x not in bread and x not in breakfast_pastry \n",
    "                and x not in dessert and x not in condiments \n",
    "                and x not in breakfast and x not in lunch]\n",
    "\n",
    "\n",
    "breadbasket['beverage'] = np.where(breadbasket.Item.isin(beverage), 1, 0)\n",
    "breadbasket['other'] = np.where(breadbasket.Item.isin(other), 1, 0)\n",
    "breadbasket['kids'] = np.where(breadbasket.Item.isin(kids), 1, 0)\n",
    "breadbasket['snacks'] = np.where(breadbasket.Item.isin(snacks), 1, 0)\n",
    "breadbasket['bread'] = np.where(breadbasket.Item.isin(bread), 1, 0)\n",
    "breadbasket['breakfast_pastry'] = np.where(breadbasket.Item.isin(breakfast_pastry), 1, 0)\n",
    "breadbasket['dessert'] = np.where(breadbasket.Item.isin(dessert), 1, 0)\n",
    "breadbasket['condiments'] = np.where(breadbasket.Item.isin(condiments), 1, 0)\n",
    "breadbasket['breakfast'] = np.where(breadbasket.Item.isin(breakfast), 1, 0)\n",
    "breadbasket['lunch'] = np.where(breadbasket.Item.isin(lunch), 1, 0)\n",
    "breadbasket['other_food'] = np.where(breadbasket.Item.isin(other_food), 1, 0)\n",
    "breadbasket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing the Data**\n",
    "\n",
    "The first bit of work we will do to process the data is to aggregate by transaction. This will give us the count of each category per transaction. We will use the groupby function to find the sum in each transaction. We group by the datetime as well since we want to keep this column after the aggregation. This should not be a problem since a transaction number and a datetime uniquely identifies each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Item</th>\n",
       "      <th>beverage</th>\n",
       "      <th>other</th>\n",
       "      <th>kids</th>\n",
       "      <th>snacks</th>\n",
       "      <th>bread</th>\n",
       "      <th>breakfast_pastry</th>\n",
       "      <th>dessert</th>\n",
       "      <th>condiments</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>lunch</th>\n",
       "      <th>other_food</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transaction</th>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2016-10-30 09:58:11</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>09:58:11</td>\n",
       "      <td>Bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-10-30 10:05:34</th>\n",
       "      <td>2016-10-302016-10-30</td>\n",
       "      <td>10:05:3410:05:34</td>\n",
       "      <td>ScandinavianScandinavian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-10-30 10:07:57</th>\n",
       "      <td>2016-10-302016-10-302016-10-30</td>\n",
       "      <td>10:07:5710:07:5710:07:57</td>\n",
       "      <td>Hot chocolateJamCookies</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2016-10-30 10:08:41</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:08:41</td>\n",
       "      <td>Muffin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>2016-10-30 10:13:03</th>\n",
       "      <td>2016-10-302016-10-302016-10-30</td>\n",
       "      <td>10:13:0310:13:0310:13:03</td>\n",
       "      <td>CoffeePastryBread</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Date  \\\n",
       "Transaction DateTime                                              \n",
       "1           2016-10-30 09:58:11                      2016-10-30   \n",
       "2           2016-10-30 10:05:34            2016-10-302016-10-30   \n",
       "3           2016-10-30 10:07:57  2016-10-302016-10-302016-10-30   \n",
       "4           2016-10-30 10:08:41                      2016-10-30   \n",
       "5           2016-10-30 10:13:03  2016-10-302016-10-302016-10-30   \n",
       "\n",
       "                                                     Time  \\\n",
       "Transaction DateTime                                        \n",
       "1           2016-10-30 09:58:11                  09:58:11   \n",
       "2           2016-10-30 10:05:34          10:05:3410:05:34   \n",
       "3           2016-10-30 10:07:57  10:07:5710:07:5710:07:57   \n",
       "4           2016-10-30 10:08:41                  10:08:41   \n",
       "5           2016-10-30 10:13:03  10:13:0310:13:0310:13:03   \n",
       "\n",
       "                                                     Item  beverage  other  \\\n",
       "Transaction DateTime                                                         \n",
       "1           2016-10-30 09:58:11                     Bread         0      0   \n",
       "2           2016-10-30 10:05:34  ScandinavianScandinavian         0      0   \n",
       "3           2016-10-30 10:07:57   Hot chocolateJamCookies         1      0   \n",
       "4           2016-10-30 10:08:41                    Muffin         0      0   \n",
       "5           2016-10-30 10:13:03         CoffeePastryBread         1      0   \n",
       "\n",
       "                                 kids  snacks  bread  breakfast_pastry  \\\n",
       "Transaction DateTime                                                     \n",
       "1           2016-10-30 09:58:11     0       0      1                 0   \n",
       "2           2016-10-30 10:05:34     0       0      2                 0   \n",
       "3           2016-10-30 10:07:57     0       0      0                 0   \n",
       "4           2016-10-30 10:08:41     0       0      0                 1   \n",
       "5           2016-10-30 10:13:03     0       0      1                 1   \n",
       "\n",
       "                                 dessert  condiments  breakfast  lunch  \\\n",
       "Transaction DateTime                                                     \n",
       "1           2016-10-30 09:58:11        0           0          0      0   \n",
       "2           2016-10-30 10:05:34        0           0          0      0   \n",
       "3           2016-10-30 10:07:57        1           1          0      0   \n",
       "4           2016-10-30 10:08:41        0           0          0      0   \n",
       "5           2016-10-30 10:13:03        0           0          0      0   \n",
       "\n",
       "                                 other_food  \n",
       "Transaction DateTime                         \n",
       "1           2016-10-30 09:58:11           0  \n",
       "2           2016-10-30 10:05:34           0  \n",
       "3           2016-10-30 10:07:57           0  \n",
       "4           2016-10-30 10:08:41           0  \n",
       "5           2016-10-30 10:13:03           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread_group = breadbasket.groupby(['Transaction','DateTime']).sum()\n",
    "bread_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the transaction number and the datetime are indices in this aggregated dataset. If we would like to use the information in these columns, we would have to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bread_group.reset_index(level=['DateTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will generate a column for day of week and for hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "Saturday     2068\n",
       "Friday       1488\n",
       "Sunday       1264\n",
       "Thursday     1252\n",
       "Tuesday      1203\n",
       "Monday       1135\n",
       "Wednesday    1121\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread_group['hour'] = bread_group.DateTime.dt.hour\n",
    "bread_group['day'] = bread_group.DateTime.dt.day_name()\n",
    "bread_group.day.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturday has the most transactions of any weekday by far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "11    1445\n",
       "12    1347\n",
       "10    1267\n",
       "13    1163\n",
       "14    1130\n",
       "9     1007\n",
       "15     924\n",
       "16     583\n",
       "8      375\n",
       "17     160\n",
       "18      52\n",
       "19      34\n",
       "7       16\n",
       "20      15\n",
       "22       7\n",
       "23       3\n",
       "21       2\n",
       "1        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread_group.hour.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 am has the most transactions followed by noon and 10 am.\n",
    "\n",
    "Now let's create dummy variables out of the day column and drop all other non numeric columns to prepare our dataset for the ML algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bread_days = pd.get_dummies(data=bread_group, columns=['day'])\n",
    "bread_days.drop(columns='DateTime', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some More Transformations - PCA\n",
    "\n",
    "Our plan here is to use k-means clustering. However, an important note on k-means clustering is that it does not respond well to dummy variable columns. Therefore, our best option is to transform the data using principal component analysis or PCA. What PCA does is project our data onto a lower dimensional subspace. The new data will typically reduce the dimensions of our original data and will therefore, contain less variables. The first dimension will explain the most amount of variation in the data and subsequent components will explain less and less variation. This transformation will provide us with a smaller amount of continuous variables that we can cluster more effectively.\n",
    "\n",
    "Here we chose to generate 4 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2016-10-30'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m      4\u001b[39m pca = PCA(n_components=\u001b[32m4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m principalComponents = \u001b[43mpca\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbread_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m principalDf = pd.DataFrame(data = principalComponents ,columns = [\u001b[33m'\u001b[39m\u001b[33mpc1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpc2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpc3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpc4\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Assuming your DataFrame is named 'df' and the date column is 'Date'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:466\u001b[39m, in \u001b[36mPCA.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    445\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     U, S, _, X, x_is_centered, xp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         U = U[:, : \u001b[38;5;28mself\u001b[39m.n_components_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:503\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    494\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPCA with svd_solver=\u001b[39m\u001b[33m'\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not supported for Array API inputs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m     )\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_svd_solver = \u001b[38;5;28mself\u001b[39m.svd_solver\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\sklearn\\utils\\validation.py:971\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[32m    967\u001b[39m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[32m    968\u001b[39m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[32m    969\u001b[39m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[32m    970\u001b[39m     new_dtype = dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     array = \u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[32m    973\u001b[39m     dtype = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\generic.py:6665\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6659\u001b[39m     results = [\n\u001b[32m   6660\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6661\u001b[39m     ]\n\u001b[32m   6663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6664\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6665\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6666\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:449\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    447\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utilizador\\.pyenv\\pyenv-win\\versions\\3.12.10\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '2016-10-30'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "principalComponents = pca.fit_transform(bread_days)\n",
    "principalDf = pd.DataFrame(data = principalComponents ,columns = ['pc1', 'pc2', 'pc3', 'pc4'])\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and the date column is 'Date'\n",
    "columns_to_use = [col for col in pca.columns if col not in ['Date', 'OtherNonNumericColumns']]\n",
    "\n",
    "# Apply your transformation/PCA only to the numeric columns\n",
    "pca_data = principalDf[columns_to_use]\n",
    "# Then scale or fit PCA on pca_data\n",
    "principalDf.head()           \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm - K-Means Clustering\n",
    "\n",
    "We are now ready to cluster the data using k-means. We chose to create 5 clusters. The choice is normally arbitrary though there are ways to optimize the number of clusters. Here, the choice is more driven by the number of transaction clusters we would like to create. Two clusters would definitely be too few to capture meaningful differences while 10 is certainly too many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63146200e+00,  5.06638014e-02,  2.89304459e-02,\n",
       "         7.19925427e-03],\n",
       "       [-4.42371509e+00, -8.64897829e-02,  1.99163392e-02,\n",
       "        -1.07060028e-02],\n",
       "       [ 3.46747051e+00, -5.43764931e-02, -3.01346671e-02,\n",
       "        -3.01326448e-03],\n",
       "       [-2.29584237e+00,  3.82205465e-02,  1.87745961e-02,\n",
       "         1.46931638e-02],\n",
       "       [-3.07237949e-01, -2.62397308e-02, -3.66405545e-02,\n",
       "        -1.44834332e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "bread_clusters = kmeans.fit(principalDf)\n",
    "bread_clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the labels back to our original data so we can do some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>beverage</th>\n",
       "      <th>other</th>\n",
       "      <th>kids</th>\n",
       "      <th>snacks</th>\n",
       "      <th>bread</th>\n",
       "      <th>breakfast_pastry</th>\n",
       "      <th>dessert</th>\n",
       "      <th>condiments</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>lunch</th>\n",
       "      <th>other_food</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>09:58:11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bread</td>\n",
       "      <td>2016-10-30 09:58:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>2016-10-30 10:05:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:05:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>2016-10-30 10:05:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Hot chocolate</td>\n",
       "      <td>2016-10-30 10:07:57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>10:07:57</td>\n",
       "      <td>3</td>\n",
       "      <td>Jam</td>\n",
       "      <td>2016-10-30 10:07:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Transaction           Item            DateTime  \\\n",
       "0  2016-10-30  09:58:11            1          Bread 2016-10-30 09:58:11   \n",
       "1  2016-10-30  10:05:34            2   Scandinavian 2016-10-30 10:05:34   \n",
       "2  2016-10-30  10:05:34            2   Scandinavian 2016-10-30 10:05:34   \n",
       "3  2016-10-30  10:07:57            3  Hot chocolate 2016-10-30 10:07:57   \n",
       "4  2016-10-30  10:07:57            3            Jam 2016-10-30 10:07:57   \n",
       "\n",
       "   beverage  other  kids  snacks  bread  breakfast_pastry  dessert  \\\n",
       "0         0      0     0       0      1                 0        0   \n",
       "1         0      0     0       0      1                 0        0   \n",
       "2         0      0     0       0      1                 0        0   \n",
       "3         1      0     0       0      0                 0        0   \n",
       "4         0      0     0       0      0                 0        0   \n",
       "\n",
       "   condiments  breakfast  lunch  other_food  labels  \n",
       "0           0          0      0           0       3  \n",
       "1           0          0      0           0       3  \n",
       "2           0          0      0           0       3  \n",
       "3           0          0      0           0       3  \n",
       "4           1          0      0           0       3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread_days['labels'] = bread_clusters.fit_predict(principalDf)\n",
    "bread_days.reset_index('Transaction', inplace=True)\n",
    "bread_merged = pd.merge(breadbasket, bread_days[['Transaction', 'labels']], on='Transaction', how='outer')\n",
    "bread_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's so some analysis on the clusters. First let's look at how many transactions we have per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5296\n",
       "3    4446\n",
       "1    4041\n",
       "0    3932\n",
       "4    3578\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread_merged.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest cluster is the 5th cluster (our clusters are numbered 0 through 4).\n",
    "\n",
    "One interesting thing to check is whether the clusters captured a different type of transaction by looking at the hour breakdown for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1128</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "labels     0    1     2     3    4\n",
       "hour                              \n",
       "1          0    0     0     1    0\n",
       "7          0    0     0    16    0\n",
       "8          0    0     0   375    0\n",
       "9          0    0     0   982   25\n",
       "10         0    0     0  1004  263\n",
       "11      1111    0     0     0  334\n",
       "12      1080    0     0     0  267\n",
       "13         0    0  1130     0   33\n",
       "14         0    0  1128     0    2\n",
       "15         0  924     0     0    0\n",
       "16         0  583     0     0    0\n",
       "17         0  160     0     0    0\n",
       "18         0   52     0     0    0\n",
       "19         0   34     0     0    0\n",
       "20         0   15     0     0    0\n",
       "21         0    2     0     0    0\n",
       "22         0    7     0     0    0\n",
       "23         0    3     0     0    0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(bread_days.hour,bread_days.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see a separation. Clusters 0, 2, and 4 center around noon. Cluster 1 is an early morning cluster. Cluster 3 is an evening cluster.\n",
    "\n",
    "We can do the same analysis for day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>358</td>\n",
       "      <td>269</td>\n",
       "      <td>355</td>\n",
       "      <td>326</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>243</td>\n",
       "      <td>232</td>\n",
       "      <td>250</td>\n",
       "      <td>315</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>441</td>\n",
       "      <td>411</td>\n",
       "      <td>506</td>\n",
       "      <td>393</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>297</td>\n",
       "      <td>209</td>\n",
       "      <td>304</td>\n",
       "      <td>295</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>287</td>\n",
       "      <td>194</td>\n",
       "      <td>264</td>\n",
       "      <td>387</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>293</td>\n",
       "      <td>223</td>\n",
       "      <td>271</td>\n",
       "      <td>300</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>225</td>\n",
       "      <td>213</td>\n",
       "      <td>283</td>\n",
       "      <td>329</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "labels       0    1    2    3    4\n",
       "day                               \n",
       "Friday     358  269  355  326  160\n",
       "Monday     243  232  250  315   95\n",
       "Saturday   441  411  506  393  224\n",
       "Sunday     297  209  304  295  127\n",
       "Thursday   287  194  264  387  120\n",
       "Tuesday    293  223  271  300  116\n",
       "Wednesday  225  213  283  329   71"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(bread_group.day,bread_days.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cluster 1 (the early morning cluster), the disparity between the weekends and the weekdays is small. While in the clusters that center around later times, there seem to be more transactions during the weekends.\n",
    "\n",
    "Let's also look at the top 5 products per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels  Item         \n",
       "0       Bread             893\n",
       "        Coffee            821\n",
       "        NONE              185\n",
       "        Cake              164\n",
       "        Pastry            164\n",
       "1       Coffee            927\n",
       "        Bread             560\n",
       "        Tea               382\n",
       "        Cake              328\n",
       "        Hot chocolate     183\n",
       "2       Coffee           1188\n",
       "        Bread             677\n",
       "        Tea               402\n",
       "        Sandwich          381\n",
       "        Cake              302\n",
       "3       Coffee           1163\n",
       "        Bread            1027\n",
       "        Pastry            389\n",
       "        Medialuna         260\n",
       "        Tea               198\n",
       "4       Coffee           1372\n",
       "        Tea               290\n",
       "        Hot chocolate     177\n",
       "        Bread             168\n",
       "        Pastry            149\n",
       "Name: counts, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = bread_merged.groupby(['labels']).Item.value_counts()\n",
    "b = a.to_frame(\"counts\").reset_index()\n",
    "b.set_index(\"Item\", inplace=True)\n",
    "b.groupby('labels').counts.nlargest(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While tea and coffee are popular in all 3 clusters, the morning cluster (Cluster 1) contains only bread, beverages and breakfast pastries. Clusters 0 and 2 are afternoon cluster and contain cake and sandwiches as top items. Cluster 3 is also an afternoon cluster and contains more desserts.\n",
    "\n",
    "We can use this data to run promotions for certain items like cake and sandwiches at certain hours to increase our sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
